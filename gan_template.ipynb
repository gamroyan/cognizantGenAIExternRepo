{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2dfee73",
   "metadata": {},
   "source": [
    "# GANs Image Generation\n",
    "\n",
    "In this notebook, we will explore how Generative Adversarial Networks (GANs) generate images. We will use a pretrained GAN model (BigGAN) to generate images from random noise.\n",
    "\n",
    "## Instructions\n",
    "1. Run the code below to generate an image from random noise.\n",
    "2. Modify the latent vector to generate different images.\n",
    "3. Experiment with generating different images by altering the latent vector and visualizing the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c780e07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gayaneamroyan/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c1448e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
    "                                       save_as_images)\n",
    "\n",
    "# Load pretrained BigGAN model\n",
    "model = BigGAN.from_pretrained('biggan-deep-256')\n",
    "\n",
    "# Generate random latent vector (noise)\n",
    "truncation = 0.4\n",
    "class_vector = one_hot_from_names(['soap bubble', 'coffee', 'orange'], batch_size=3)\n",
    "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=3)\n",
    "\n",
    "noise_vector = torch.from_numpy(noise_vector)\n",
    "class_vector = torch.from_numpy(class_vector)\n",
    "\n",
    "# Generate image\n",
    "with torch.no_grad():\n",
    "    generated_image = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "# Convert the tensor to a displayable image\n",
    "save_as_images(generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac3feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random latent vectors\n",
    "noise_vector = torch.randn(3, 128)  # 3 images, 128-dim latent vector\n",
    "class_vector = one_hot_from_names(['soap bubble', 'coffee', 'mushroom'], batch_size=3)\n",
    "class_vector = torch.from_numpy(class_vector)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_image = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "save_as_images(generated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff7b1ff",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "**Introduction** \n",
    "\n",
    "A GAN (Generative Adversarial Network) is a type of machine learning model used to generate new output based on existing data. A GAN consists of two components: a generator, which develops fake images/data from random noise, and a discriminator, which evaluates this data and distinguishes it from real or fake. These two components work together, as the disciminator gets better at pointing out the realness of a generated image from the generator, the generator learns to create highly realistic outputs. Through this process, the GAN learns to produce higher-quality and unique output.\n",
    "\n",
    "**Experiment Summary**\n",
    "\n",
    "I chose to use a pre-trained BigGAN model for this experiment. BigGAN builds on the traditional GAN architecture with larger batch sizes and different training techniques, which helps develop very high-resolution images. I created images using a PyTorch pre-trained BigGAN my classmates found off of huggingface to do this assignment (https://github.com/huggingface/pytorch-pretrained-BigGAN/blob/master/README.md). I quickly realized that the latent vector was responsible for the variability in the images. Images were generating by inputting this latent vector into the generator. This vector represents a point in the modelâ€™s learned image space. \n",
    "\n",
    "**Observations**\n",
    "\n",
    "By testing out many vector values, I noticed that the latent vector made the pictures vary by so much in all sorts of ways. The code block above this reflection generates random latent vectors for all three items that are listed in the class vector. I realized that even a small shift in the latent vector and truncation produced images that varied in their color schemes, object shapes, and lighting conditions. However, I noticed that multiple images generated with the same latent value shared a common \"look and feel.\" The three pictures I have attached were generated with the same random latent vector, and have almost the same look although they're producing images of different items (the pictures I'm referring to are output_0.png, output_1.png, and output_2.png in my repository). These images have warm colors, smooth lines, and are almost cartoonish. This is wildly different than any other set of images I generated with the random vector values. These three images share similar characteristics, which can be attributed to sharing the same latent vector. The consistency among these images really highlights how GANs organize the latent space, as similar vectors correspond to related visual features. In this case, the shared vector likely encoded stylistic preferences such as line smoothness or saturation. \n",
    "\n",
    "**Reflection**\n",
    "\n",
    "I learned an increible amount about how GANs generate new data. I had no prior experience to machine learning before this course, so almost everything taught in the lesson is new and very valuable to me. One aspect of GANs that really intrigues me is how the generator and the discriminator work together and essentially train one another. I'm also drawn to the creative aspect of GANs. Although they're vector-based programs that are fully data-driven, there's so much creativity with what output you want to produce, and how you want it to impact the world. Also, as I discussed in my observations, this project helped me understand how important the latent vector is when producing new output. However, I did notice some limitations. Some images contained minor unrealistic distortions. Most of the images were muddled and unclear what was being generated, especially when the latent-vectors were very random. Also, the interpretability of the latent space still is limited. It was really hard to predit how a specific change in the vector would affect the production of an image. Overall, this project helped me understand GANS deeply, and I'm interested in how more advanced the process could get through diverse and larger datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
